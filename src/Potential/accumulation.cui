// -*-c++-*-

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ unsigned long long int lliToUlli(long long int l)
{
  unsigned long long int u;
  asm("mov.b64    %0, %1;" : "=l"(u) : "l"(l));
  return u;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ long long int ulliToLli(unsigned long long int u)
{
  long long int l;
  asm("mov.b64    %0, %1;" : "=l"(l) : "l"(u));
  return l;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ void splitForceContribution(const float fval, const int pos,
                                                       int* sh_primary, int* sh_overflow_active,
                                                       int* overflow, int gmem_offset) {
  int ival;
  if (fabsf(fval) >= max_int_accumulation_f) {
    const int spillover = fval / max_int_accumulation_f;
    ival = __float2int_rn(fval - ((float)(spillover) * max_int_accumulation_f));
    atomicAdd(&overflow[gmem_offset + pos], spillover);

    // No atomic needed as this just sets the value, which started as zero, to one
    sh_overflow_active[pos / warp_size_int] = 1;
  }
  else {
    ival = __float2int_rn(fval);
  }
  const int prim_old = atomicAdd(&sh_primary[pos], ival);
  const int prim_old_plus_ival = prim_old + ival;
  if ((prim_old ^ prim_old_plus_ival) < 0 && (prim_old ^ ival) >= 0) {
    atomicAdd(&overflow[gmem_offset + pos], (1 - (2 * (ival < 0))) * 2);
    sh_overflow_active[pos / warp_size_int] = 1;
  }
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 convertSplitFixedPrecision(const float fval) {
  int2 result = { 0, 0 };
  if (fabsf(fval) >= max_int_accumulation_f) {
    const int spillover = fval / max_int_accumulation_f;
    result.x = __float2int_rn(fval - ((float)(spillover) * max_int_accumulation_f));
    result.y = spillover;
  }
  else {
    result.x = __float2int_rn(fval);
    result.y = 0;
  }
  return result;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ void addSplitFixedPrecision(const int2 ival, const int pos,
                                                       int* sh_primary, int* sh_overflow_active,
                                                       int* overflow, int gmem_offset) {
  const int prim_old = atomicAdd(&sh_primary[pos], ival.x);
  const int prim_old_plus_x = prim_old + ival.x;
  int ival_y = ival.y;
  ival_y += ((prim_old ^ prim_old_plus_x) < 0 && (prim_old ^ ival.x) >= 0) *
            (1 - (2 * (ival.x < 0))) * 2;    
  if (ival_y) {
    atomicAdd(&overflow[gmem_offset + pos], ival_y);
  }
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 combineSplitFixedPrecision(const int2 a, const int2 b) {
  int2 result = { a.x + b.x, a.y + b.y };
  result.y += (1 - (2 * (b.x < 0))) * ((a.x ^ result.x) < 0 && (a.x ^ b.x) >= 0) * 2;
  return result;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 antiCombineSplitFixedPrecision(const int2 a, const int2 b) {
  int2 result = { a.x + b.x, a.y + b.y };
  if ((b.x > 0 && result.x < a.x) || b.x < 0 && result.x > a.x) {
    result.y += (1 - (2 * (b.x < 0))) * 2 * ((b.x > 0 && result.x < a.x) +
                                             (b.x < 0 && result.x > a.x));
  }
  result.x = -result.x;
  result.y = -result.y;
  return result;
}
