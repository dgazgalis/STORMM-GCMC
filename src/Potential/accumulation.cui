// -*-c++-*-

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ unsigned long long int llitoulli(long long int l)
{
  unsigned long long int u;
  asm("mov.b64    %0, %1;" : "=l"(u) : "l"(l));
  return u;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ long long int ullitolli(unsigned long long int u)
{
  long long int l;
  asm("mov.b64    %0, %1;" : "=l"(l) : "l"(u));
  return l;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ void splitForceContribution(const float fval, const int pos,
                                                       int* sh_primary, int* sh_overflow_active,
                                                       int* overflow) {
  int ival;
  if (fabsf(fval) >= max_int_accumulation_f) {
    const int spillover = fval / max_int_accumulation_f;
    ival = __float2int_rn(fval - ((float)(spillover) * max_int_accumulation_f));
    atomicAdd(&overflow[pos], spillover);

    // No atomic needed as this just sets the value, which started as zero, to one
    sh_overflow_active[pos / warp_size_int] = 1;
  }
  else {
    ival = __float2int_rn(fval);
  }
  const int prim_old = atomicAdd(&sh_primary[pos], ival);
  if ((ival > 0 && prim_old + ival < prim_old) || (ival < 0 && prim_old + ival > prim_old)) {
    atomicAdd(&overflow[pos],
              (1 - (2 * (ival < 0))) * 2 * ((ival > 0 && prim_old + ival < prim_old) +
                                            (ival < 0 && prim_old + ival > prim_old)));
    sh_overflow_active[pos / warp_size_int] = 1;
  }
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 convertSplitFixedPrecision(const float fval) {
  int2 result = { 0, 0 };
  if (fabsf(fval) >= max_int_accumulation_f) {
    const int spillover = fval / max_int_accumulation_f;
    result.x = __float2int_rn(fval - ((float)(spillover) * max_int_accumulation_f));
    result.y = spillover;
  }
  else {
    result.x = __float2int_rn(fval);
    result.y = 0;
  }
  return result;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ void addSplitFixedPrecision(const int2 ival, const int pos,
                                                       int* sh_primary, int* sh_overflow_active,
                                                       int* overflow) {
  const int prim_old = atomicAdd(&sh_primary[pos], ival.x);
  int ival_y = ival.y;
  if ((ival.x > 0 && prim_old + ival.x < prim_old) ||
      (ival.x < 0 && prim_old + ival.x > prim_old)) {
    ival_y += (1 - (2 * (ival.x < 0))) * 2 * ((ival.x > 0 && prim_old + ival.x < prim_old) +
                                              (ival.x < 0 && prim_old + ival.x > prim_old));
  }
  if (ival_y) {
    atomicAdd(&overflow[pos], ival_y);
  }
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 combineSplitFixedPrecision(const int2 a, const int2 b) {
  int2 result = { a.x + b.x, a.y + b.y };
  if ((b.x > 0 && result.x < a.x) || b.x < 0 && result.x > a.x) {
    result.y += (1 - (2 * (b.x < 0))) * 2 * ((b.x > 0 && result.x < a.x) +
                                             (b.x < 0 && result.x > a.x));
  }
  return result;
}

//-------------------------------------------------------------------------------------------------
__device__ __forceinline__ int2 antiCombineSplitFixedPrecision(const int2 a, const int2 b) {
  int2 result = { a.x + b.x, a.y + b.y };
  if ((b.x > 0 && result.x < a.x) || b.x < 0 && result.x > a.x) {
    result.y += (1 - (2 * (b.x < 0))) * 2 * ((b.x > 0 && result.x < a.x) +
                                             (b.x < 0 && result.x > a.x));
  }
  result.x = -result.x;
  result.y = -result.y;
  return result;
}
