// -*-c++-*-
#include "copyright.h"

#define EXCL_GMEM_OFFSET  (blockIdx.x * gmem_r.max_atoms)

/// \brief Compute the Generalized Born radii for all particles in all systems.
///
/// \param poly_nbk  Condensed non-bonded parameter tables and atomic properties for all systems
/// \param ngb_kit   Neck Generalized Born parameters
/// \param ctrl      Molecular mechanics control data
/// \param poly_psw  Coordinates and forces for all particles
/// \param gmem_r    Workspaces for each thread block
__global__ void __launch_bounds__(small_block_size, GBRADII_KERNEL_BLOCKS_MULTIPLIER)
KERNEL_NAME(const SyNonbondedKit<TCALC, TCALC2> poly_nbk, MMControlKit<TCALC> ctrl,
            PsSynthesisWriter poly_psw, CacheResourceKit<TCALC> gmem_r,
            ISWorkspaceKit<TCALC> isw) {

  // Coordinate and properties of particles are copied into special, L1-cached arrays of GMEM used
  // exclusively by this block.
  __shared__ TCALC sh_tile_xcog[small_block_max_imports];
  __shared__ TCALC sh_tile_ycog[small_block_max_imports];
  __shared__ TCALC sh_tile_zcog[small_block_max_imports];
  __shared__ TCALC sh_tile_tpts[small_block_max_imports];
  __shared__ TCALC sh_gbeff_radii[small_block_max_atoms];
#ifdef COMPUTE_FORCE
#  ifdef TCALC_IS_SINGLE
#    ifdef SPLIT_FORCE_ACCUMULATION
  __shared__ int sh_sum_deijda[small_block_max_atoms];
  __shared__ int sh_sum_deijda_overflow[small_block_max_atoms];
  __shared__ int sh_xfrc[small_block_max_atoms];
  __shared__ int sh_yfrc[small_block_max_atoms];
  __shared__ int sh_zfrc[small_block_max_atoms];
  __shared__ int sh_xfrc_overflow[small_block_max_atoms];
  __shared__ int sh_yfrc_overflow[small_block_max_atoms];
  __shared__ int sh_zfrc_overflow[small_block_max_atoms];
#    else
  __shared__ llint sh_sum_deijda[small_block_max_atoms];
  __shared__ llint sh_xfrc[small_block_max_atoms];
  __shared__ llint sh_yfrc[small_block_max_atoms];
  __shared__ llint sh_zfrc[small_block_max_atoms];
#    endif
#  else
  __shared__ llint sh_sum_deijda[small_block_max_atoms];
  __shared__ int sh_sum_deijda_overflow[small_block_max_atoms];
  __shared__ llint sh_xfrc[small_block_max_atoms];
  __shared__ llint sh_yfrc[small_block_max_atoms];
  __shared__ llint sh_zfrc[small_block_max_atoms];
  __shared__ int sh_xfrc_overflow[small_block_max_atoms];
  __shared__ int sh_yfrc_overflow[small_block_max_atoms];
  __shared__ int sh_zfrc_overflow[small_block_max_atoms];
#  endif
#endif
  __shared__ int nbwu_map[tile_groups_wu_abstract_length];
  __shared__ int gbdwu_idx;

  // Read the non-bonded work unit abstracts
  if (threadIdx.x == 0) {
    gbdwu_idx = blockIdx.x;
  }
  __syncthreads();
  while (gbdwu_idx < poly_nbk.nnbwu) {
    if (threadIdx.x < tile_groups_wu_abstract_length) {
      nbwu_map[threadIdx.x] =__ldcv(&poly_nbk.nbwu_abstracts[(gbdwu_idx *
                                                              tile_groups_wu_abstract_length) +
                                                             threadIdx.x]);
    }
    __syncthreads();

    // Import atomic coordinates and properties.  Each warp will handle importing one of the
    // Cartesian coordinates or properties of as many tile sides as it can handle, in order to
    // get the most threads reaching out to global memory.
    const int tile_sides_per_warp = (warp_size_int / tile_length);
    const int warp_idx = (threadIdx.x >> warp_bits);
    const int warp_lane_idx = (threadIdx.x & warp_bits_mask_int);
    const int tile_side_offset = warp_lane_idx / tile_length;
    const int import_count = nbwu_map[0];
    int pos = (tile_sides_per_warp * warp_idx) + tile_side_offset;
#ifdef TCALC_IS_SINGLE
    pos = loadTileCoordinates(pos, 0, nbwu_map, poly_psw.xcrd, &gmem_r.xcrd[EXCL_GMEM_OFFSET],
                              sh_tile_xcog, poly_psw.gpos_scale_f);
    pos = loadTileCoordinates(pos, 1, nbwu_map, poly_psw.ycrd, &gmem_r.ycrd[EXCL_GMEM_OFFSET],
                              sh_tile_ycog, poly_psw.gpos_scale_f);
    pos = loadTileCoordinates(pos, 2, nbwu_map, poly_psw.zcrd, &gmem_r.zcrd[EXCL_GMEM_OFFSET],
                              sh_tile_zcog, poly_psw.gpos_scale_f);
    pos = loadTileProperty(pos, 3, nbwu_map, poly_nbk.charge, &gmem_r.charges[EXCL_GMEM_OFFSET],
                           SQRT_FUNC(poly_nbk.coulomb));
    pos = loadTileProperty(pos, 4, nbwu_map, poly_nbk.lj_idx, &gmem_r.lj_idx[EXCL_GMEM_OFFSET]);
#else
    pos = loadTileCoordinates(pos, 0, nbwu_map, poly_psw.xcrd, &gmem_r.xcrd[EXCL_GMEM_OFFSET],
                              poly_psw.xcrd_ovrf, &gmem_r.xcrd_ovrf[EXCL_GMEM_OFFSET],
                              sh_tile_xcog, poly_psw.gpos_scale);
    pos = loadTileCoordinates(pos, 1, nbwu_map, poly_psw.ycrd, &gmem_r.ycrd[EXCL_GMEM_OFFSET],
                              poly_psw.ycrd_ovrf, &gmem_r.ycrd_ovrf[EXCL_GMEM_OFFSET],
                              sh_tile_ycog, poly_psw.gpos_scale);
    pos = loadTileCoordinates(pos, 2, nbwu_map, poly_psw.zcrd, &gmem_r.zcrd[EXCL_GMEM_OFFSET],
                              poly_psw.zcrd_ovrf, &gmem_r.zcrd_ovrf[EXCL_GMEM_OFFSET],
                              sh_tile_zcog, poly_psw.gpos_scale);
    pos = loadTileProperty(pos, 3, nbwu_map, poly_nbk.charge, &gmem_r.charges[EXCL_GMEM_OFFSET],
                           SQRT_FUNC(poly_nbk.coulomb));
    pos = loadTileProperty(pos, 4, nbwu_map, poly_nbk.lj_idx, &gmem_r.lj_idx[EXCL_GMEM_OFFSET]);
#endif
    const int padded_import_count = devcRoundUp(import_count, tile_sides_per_warp);
    const int warps_per_block = blockDim.x >> warp_bits;
    const int tile_lane_idx = (threadIdx.x & tile_length_bits_mask);
#ifdef COMPUTE_ENERGY
    llint egb_acc = 0LL;
#endif
    while (pos < 4 * padded_import_count) {
      const int rel_pos = pos - (3 * padded_import_count);
      if (rel_pos < import_count) {
        const size_t read_idx = nbwu_map[rel_pos + 1] + tile_lane_idx;
        const size_t write_idx = (rel_pos * tile_length) + tile_lane_idx;

        // Compute the effective GB radii and, if applicable, begin to accumulate the energy.
        const TCALC pb_radius = __ldcs(&poly_nbk.pb_radii[read_idx]);
        const TCALC gb_radius = pb_radius - poly_nbk.gb_offset;
        const TCALC inv_gb_radius = (TCALC)(1.0) / gb_radius;
#ifdef TCALC_IS_SINGLE
        const TCALC psival = (TCALC)(__ldcs(&isw.psi[read_idx])) * isw.inv_fp_scale;
#else
        const TCALC psival = int95ToDouble(__ldcs(&isw.psi[read_idx]),
                                           __ldcs(&isw.psi_ovrf[read_idx])) * isw.inv_fp_scale;
#endif
        TCALC egbi = 0.0;
        switch (poly_nbk.igb) {
        case ImplicitSolventModel::HCT_GB:
          egbi = (TCALC)(1.0) / (inv_gb_radius + psival);
          if (egbi < (TCALC)(0.0)) {
            egbi = (TCALC)(30.0);
          }
          break;
        case ImplicitSolventModel::OBC_GB:
        case ImplicitSolventModel::OBC_GB_II:
        case ImplicitSolventModel::NECK_GB:
        case ImplicitSolventModel::NECK_GB_II:
          {
            const TCALC fipsi = psival * poly_psw.inv_frc_scale * (-gb_radius);
            egbi = (TCALC)(1.0) /
                   (inv_gb_radius -
                    (TANH_FUNC(__ldcs(&poly_nbk.gb_alpha[read_idx]) -
                               ((__ldcs(&poly_nbk.gb_beta[read_idx]) -
                                 (__ldcs(&poly_nbk.gb_gamma[read_idx]) * fipsi)) * fipsi)) /
                     pb_radius));
          }
          break;
        case ImplicitSolventModel::NONE:
          break;
        }
        sh_gbeff_radii[write_idx] = egbi;
        const TCALC atomq = __ldcs(&poly_nbk.charge[read_idx]);
        __stwb(&gmem_r.charges[EXCL_GMEM_OFFSET + write_idx], atomq);
        const TCALC expmkf = EXP_FUNC(-default_gb_kscale * poly_nbk.kappa * egbi) /
                             poly_nbk.dielectric;
        const TCALC dielfac = (TCALC)(1.0) - expmkf;
        const TCALC atmq2h = (TCALC)(0.5) * atomq * atomq * poly_nbk.coulomb;
#ifdef COMPUTE_ENERGY
        const TCALC atmqd2h = atmq2h * dielfac;
        egb_acc += (-atmqd2h / egbi) * scw.nrg_scale_f;
#endif
#ifdef COMPUTE_FORCE
#  ifdef TCALC_IS_SINGLE
#    ifdef SPLIT_FORCE_ACCUMULATION
        const int2 ssd = floatToInt63((atmqd2h - (default_gb_kscale * isr.kappa *
                                                  atmq2h * expmkf * atomi_radius)) *
                                      poly_psw.frc_scale_f);
        sh_sum_deijda[write_idx] = ssd.x;
        sh_sum_deijda_overflow[write_idx] = ssd.y;
#    else
        sh_sum_deijda[write_idx] = LLCONV_FUNC((atmqd2h - (default_gb_kscale * isr.kappa *
                                                           atmq2h * expmkf * atomi_radius)) *
                                               poly_psw.frc_scale_f);
#    endif
#  else
        const int95_t ssd = floatToInt63((atmqd2h - (default_gb_kscale * isr.kappa *
                                                     atmq2h * expmkf * atomi_radius)) *
                                         poly_psw.frc_scale_f);
        sh_sum_deijda[write_idx] = ssd.x;
        sh_sum_deijda_overflow[write_idx] = ssd.y;
#  endif
#endif
      }
      pos += tile_sides_per_warp * warps_per_block;
    }
    while (pos < 5 * padded_import_count) {
      const int rel_pos = pos - (4 * padded_import_count);
      if (rel_pos < import_count) {
        const size_t read_idx = (size_t)(nbwu_map[rel_pos + 1] + tile_lane_idx);
        const size_t write_idx = (size_t)((rel_pos * tile_length) + tile_lane_idx +
                                          EXCL_GMEM_OFFSET);

        // Fuse the Lennard-Jones and Neck Generalized Born indices.  Provide up to 65,536 types
        // for each in a single 32-bit integer.
        const int lj_idx = __ldcs(&poly_nbk.lj_idx[read_idx]);
        const int gb_neck_idx = __ldcs(&poly_nbk.neck_gb_idx[read_idx]);
        const int fused_idx = ((gb_neck_idx << 16) | lj_idx);
        __stwb(&gmem_r.lj_idx[write_idx], fused_idx);
      }
      pos += tile_sides_per_warp * warps_per_block;
    }
    __syncthreads();


    
    // Increment the work unit counter
    __syncthreads();
    if (threadIdx.x == 0) {
      const size_t prog_counter_idx = (ctrl.step & twice_warp_bits_mask_int);
      gbdwu_idx = atomicAdd(&ctrl.gbdwu_progress[prog_counter_idx], 1);
    }
    __syncthreads();
  }
}

#undef EXCL_GMEM_OFFSET
