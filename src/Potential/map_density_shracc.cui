// -*-c++-*-
#include "copyright.h"

__global__ void __launch_bounds__(DENSITY_SPREADING_THREADS, MAPPING_BLOCKS)
KERNEL_NAME(PMIGridWriter pm_wrt, MappingResourceKit gmem_r, MMControlKit<TCALC> ctrl,
            const CellGridReader<TMAT, void, TCALC, T4> cgr,
            const SyNonbondedKit<TCALC, TCALC2> synbk) {

  // The system's cell transformation matrix, taking Cartesian coordinates into fractional space,
  // must be stored for each work unit to align particles to the particle-mesh interaction grid.
  // The storage space is tailored to meet a thread block count of 4-5, with 256 threads per block
  // and a maximum cross section of 16 cells.  Each warp will handle its own chain of cells until
  // all cell chains have been processed.

  __shared__ volatile TCALC cell_umat[9];
#ifdef ACC_MODE_DOUBLE
  __shared__ llint primary[STORAGE_VOLUME];
#else
  __shared__ int primary[STORAGE_VOLUME];
#endif
  __shared__ int overflow[STORAGE_VOLUME];
  __shared__ volatile int pmwu[density_mapping_wu_size];
  __shared__ volatile int warp_pos[DENSITY_SPREADING_THREADS >> warp_bits];
  __shared__ volatile int pmwu_idx, warp_progress;

  // Chain prefix sums to help locate atoms
  __shared__ volatile uint chain_prefix_sums[(DENSITY_SPREADING_THREADS >> warp_bits) *
                                             (max_shared_acc_atom_bearing_region_adim + 1)];
  __shared__ volatile uint chain_global_atom_limits[(DENSITY_SPREADING_THREADS >> warp_bits) *
                                                    (max_shared_acc_atom_bearing_region_adim + 1)];
  const int warp_idx = (threadIdx.x >> warp_bits);
  const int lane_idx = (threadIdx.x & warp_bits_mask_int);
  
  // The kernel executes work units containing three phases each:
  //
  // - Read the work unit and initialize the density mapping region.  Initialize all primary
  //   accumulators in __shared__.  On the first work unit loaded, initialize the block's
  //   exclusive space out in __global__ memory.
  // - Cycle through the following, devoting one warp to each chain in the work unit:
  //   * Compute the prefix sum for the chain
  //   * Read the atoms of each cell in chains along the unit cell A axis.  Compute B-splines and
  //     issue atomicAdd operations for any mapped points that fall within the density mapping
  //     region.
  // - Convert the integer accumulations in __shared__ to real-valued numbers, folding in the
  //   overflow accumulators in __global__ memory if any overflow was triggered.  Re-initialize
  //   the overflow accumulators if necessary.  Write the real-value results to the proper indices
  //   of the main grid in __global__ memory.
  if (warp_idx == 0) {
    if (threadIdx.x == 0) {
      pmwu_idx = blockIdx.x;
      warp_progress = (blockDim.x >> warp_bits);
    }
    SYNCWARP;
    if (pmwu_idx < pm_wrt.wu_count) {
      for (int pos = lane_idx; pos < density_mapping_wu_size; pos += warp_size_int) {
        pmwu[pos] = pm_wrt.work_units[(pmwu_idx * density_mapping_wu_size) + pos];
      }

      // Getting the same information again from L1 avoids the need for another SYNCWARP call
      const int sysid = pm_wrt.work_units[pmwu_idx * density_mapping_wu_size];
#if defined(STORMM_USE_CUDA) || defined(STORMM_USE_HIP) || defined(STORMM_USE_INTEL)
      if (lane_idx < 9) {
        cell_umat[lane_idx] = cgr.system_cell_umat[(sysid * warp_size_int) + lane_idx];
      }
#endif
      for (int pos = lane_idx; pos < (blockDim.x >> warp_bits); pos += warp_size_int) {
        warp_pos[pos] = pos;
      }
    }
  }
  else {

    // Initialize all critical elements of the __shared__ memory space
    for (int pos = threadIdx.x - warp_size_int; pos < gmem_r.max_grid_points;
         pos += blockDim.x - warp_size_int) {
#ifdef ACC_MODE_DOUBLE
      primary[pos] = 0LL;
#else
      primary[pos] = 0;
#endif
      overflow[pos] = 0;
    }
  }
  __syncthreads();

  // Loop over all work units.  The whole block advances one work unit at a time.  
  while (pmwu_idx < pm_wrt.wu_count) {
    
    // Each warp will now take one chain and operate on all atoms in it.  Warps will asynchronously
    // process each chain guided by a counter in __shared__.
    while (warp_pos[warp_idx] < pmwu[16]) {
      
      // Compute the chain index that the warp should operate upon.
      const int local_chain_cpos = warp_pos[warp_idx] / pmwu[5];
      const int local_chain_bpos = warp_pos[warp_idx] - (local_chain_cpos * pmwu[5]);
      int sys_chain_bpos = local_chain_bpos + pmwu[2];
      int sys_chain_cpos = local_chain_cpos + pmwu[3];
      sys_chain_bpos -= (sys_chain_bpos >= pmwu[23]) * pmwu[23];
      sys_chain_cpos -= (sys_chain_cpos >= pmwu[24]) * pmwu[24];
      const int chn_cell_idx_start = pmwu[25] +
                                     (((sys_chain_cpos * pmwu[23]) + sys_chain_bpos) * pmwu[22]);
      int cell_a_pos = pmwu[1] + lane_idx;
      cell_a_pos -= (cell_a_pos >= pmwu[22]) * pmwu[22];
      uint2 cell_lims;
      if (lane_idx < pmwu[4]) {
        cell_lims = cgr.cell_limits[chn_cell_idx_start + cell_a_pos];
      }
      else {
        cell_lims = { 0U, 0U };
      }
      int natom = (cell_lims.y >> 16);
      
      // The chain of cells in this work unit will not extend to the full length of the warp, on
      // any known architecture.  Use the typical exclusive prefix sum.
      EXCLUSIVE_WARP_PREFIXSUM(natom, lane_idx);
      const size_t prfx_idx = (warp_idx * (max_shared_acc_atom_bearing_region_adim + 1)) +
                              lane_idx;
      if (lane_idx < pmwu[4] + 1) {
        chain_global_atom_limits[prfx_idx] = cell_lims.x;
        chain_prefix_sums[prfx_idx] = natom;
      }
      SYNCWARP;
      uint atom_in_chain_pos = lane_idx;
      int cell_in_chain = (warp_idx * (max_shared_acc_atom_bearing_region_adim + 1));
      while (atom_in_chain_pos <
             chain_prefix_sums[(warp_idx *
                                (max_shared_acc_atom_bearing_region_adim + 1)) + pmwu[4]]) {
        
        // Determine which cell the atom comes from.  For any valid atom in the chain, the loop
        // will terminate before running off the end of the valid cells.
        while (atom_in_chain_pos >= chain_prefix_sums[cell_in_chain + 1]) {
          cell_in_chain++;
        }

        // Obtain the atom coordinates and compute the fractional position within the cell.
        // Translate the image's atom property field into a density.
        const uint img_idx = chain_global_atom_limits[cell_in_chain] + atom_in_chain_pos -
                             chain_prefix_sums[cell_in_chain];
        T4 crdq;
#ifdef TMAT_IS_LONG
        crdq = cgr.image[img_idx];
#else
        crdq = __ldca(&cgr.image[img_idx]);
#endif
#ifdef TMAT_IS_REAL
        const TCALC frac_a = (cell_umat[0] * crdq.x) + (cell_umat[3] * crdq.y) +
                             (cell_umat[6] * crdq.z);
        const TCALC frac_b = (cell_umat[4] * crdq.y) + (cell_umat[7] * crdq.z);
        const TCALC frac_c =                           (cell_umat[8] * crdq.z);

        // Resolve the density quantity to release the 16- or 32-byte crdq object from registers.
        TCALC q;
        switch (pm_wrt.theme) {
        case NonbondedTheme::ELECTROSTATIC:
          switch (cgr.theme) {
          case NonbondedTheme::ELECTROSTATIC:
            q = crdq.w;
            break;
          case NonbondedTheme::VAN_DER_WAALS:
            break;
          case NonbondedTheme::ALL:
            {
#  ifdef TMAT_IS_LONG
              const llint qprm_as_lli = __double_as_longlong(crdq.w);
              const int qprm_idx = (qprm_as_lli & dp_charge_index_mask);
#  else
              const int qprm_as_i = __float_as_int(crdq.w);
              const int qprm_idx = (qprm_as_i & sp_charge_index_mask);
#  endif
              q = synbk.q_params[qprm_idx];
            }
            break;
          }
          break;
        case NonbondedTheme::VAN_DER_WAALS:
          switch (cgr.theme) {
          case NonbondedTheme::ELECTROSTATIC:
            break;
          case NonbondedTheme::VAN_DER_WAALS:
            {
#  ifdef TMAT_IS_LONG
              const int tlj_idx = __double_as_longlong(crdq.w);
#  else
              const int tlj_idx = __float_as_int(crdq.w);
#  endif
              q = synbk.ljb_coeff[synbk.ljabc_offsets[pmwu[0]] +
                                  ((synbk.n_lj_types[pmwu[0]] + 1) * tlj_idx)];
#  ifdef TCALC_IS_DOUBLE
              q = sqrt((TCALC)(0.25) * q);
#  else
              q = sqrtf((TCALC)(0.25) * q);
#  endif
            }
            break;
          case NonbondedTheme::ALL:
            {
#  ifdef TMAT_IS_LONG
              const llint ljidx_as_lli = __double_as_longlong(crdq.w);
              const int tlj_idx = (ljidx_as_lli >> dp_charge_index_bits);
#  else
              const int ljidx_as_i = __float_as_int(crdq.w);
              const int tlj_idx = (ljidx_as_i >> sp_charge_index_bits);
#  endif
              q = synbk.ljb_coeff[synbk.ljabc_offsets[pmwu[0]] +
                                  ((synbk.n_lj_types[pmwu[0]] + 1) * tlj_idx)];
#  ifdef TCALC_IS_DOUBLE
              q = sqrt((TCALC)(0.25) * q);
#  else
              q = sqrtf((TCALC)(0.25) * q);
#  endif
            }
            break;
          }
          break;
        case NonbondedTheme::ALL:
          break;
        }
#else // TMAT_IS_REAL
        const TCALC crd_x = (TCALC)(crdq.x) * cgr.lpos_inv_scale;
        const TCALC crd_y = (TCALC)(crdq.y) * cgr.lpos_inv_scale;
        const TCALC crd_z = (TCALC)(crdq.z) * cgr.lpos_inv_scale;
        const TCALC frac_a = (cell_umat[0] * crd_x) + (cell_umat[3] * crd_y) +
                             (cell_umat[6] * crd_z);
        const TCALC frac_b = (cell_umat[4] * crd_y) + (cell_umat[7] * crd_z);
        const TCALC frac_c =                          (cell_umat[8] * crd_z);

        // Resolve the density quantity to release the 16- or 32-byte crdq object from registers.
        TCALC q;
        switch (pm_wrt.theme) {
        case NonbondedTheme::ELECTROSTATIC:
          switch (cgr.theme) {
          case NonbondedTheme::ELECTROSTATIC:
#  ifdef TMAT_IS_LONG
            q = __longlong_as_double(crdq.w);
#  else
            q = __int_as_float(crdq.w);
#  endif
            break;
          case NonbondedTheme::VAN_DER_WAALS:
            break;
          case NonbondedTheme::ALL:
            {
#  ifdef TMAT_IS_LONG
              const int qprm_idx = (crdq.w & dp_charge_index_mask);
#  else
              const int qprm_idx = (crdq.w & sp_charge_index_mask);
#  endif
              q = synbk.q_params[qprm_idx];
            }
            break;
          }
          break;
        case NonbondedTheme::VAN_DER_WAALS:
          switch (cgr.theme) {
          case NonbondedTheme::ELECTROSTATIC:
            break;
          case NonbondedTheme::VAN_DER_WAALS:
            {
              const int tlj_idx = crdq.w;
              q = synbk.ljb_coeff[synbk.ljabc_offsets[pmwu[0]] +
                                  ((synbk.n_lj_types[pmwu[0]] + 1) * tlj_idx)];
#  ifdef TCALC_IS_DOUBLE
              q = sqrt((TCALC)(0.25) * q);
#  else
              q = sqrtf((TCALC)(0.25) * q);
#  endif
            }
            break;
          case NonbondedTheme::ALL:
            {
#  ifdef TMAT_IS_LONG
              const int tlj_idx = (crdq.w >> dp_charge_index_bits);
#  else
              const int tlj_idx = (crdq.w >> sp_charge_index_bits);
#  endif
              q = synbk.ljb_coeff[synbk.ljabc_offsets[pmwu[0]] +
                                  ((synbk.n_lj_types[pmwu[0]] + 1) * tlj_idx)];
#  ifdef TCALC_IS_DOUBLE
              q = sqrt((TCALC)(0.25) * q);
#  else
              q = sqrtf((TCALC)(0.25) * q);
#  endif
            }
            break;
          }
          break;
        case NonbondedTheme::ALL:
          break;
        }
#endif // TMAT_IS_REAL

        // Determine the starting indices for the atom's density to map onto the local grid.
        int ida, idb, idc;
#ifdef TCALC_IS_DOUBLE
        const TCALC da = imageLocalFraction(frac_a, cgr.mesh_ticks, &ida);
        const TCALC db = imageLocalFraction(frac_b, cgr.mesh_ticks, &idb);
        const TCALC dc = imageLocalFraction(frac_c, cgr.mesh_ticks, &idc);
#else
        const TCALC da = imageLocalFractionf(frac_a, cgr.mesh_ticks, &ida);
        const TCALC db = imageLocalFractionf(frac_b, cgr.mesh_ticks, &idb);
        const TCALC dc = imageLocalFractionf(frac_c, cgr.mesh_ticks, &idc);
#endif
        const int local_grid_offset = pmwu[4] - pmwu[10];
        ida += (cell_in_chain - (warp_idx * (max_shared_acc_atom_bearing_region_adim + 1)) -
                local_grid_offset) * cgr.mesh_ticks;
        idb += (local_chain_bpos - local_grid_offset) * cgr.mesh_ticks;
        idc += (local_chain_cpos - local_grid_offset) * cgr.mesh_ticks;
        
        // Compute B-spline coefficients given the deltas.
        TCALC bspln_a_knots[ORDER], bspln_b_knots[ORDER], bspln_c_knots[ORDER];
#if ORDER == 4
        devcBSpline4(da, bspln_a_knots);
        devcBSpline4(db, bspln_b_knots);
        devcBSpline4(dc, bspln_c_knots);
#elif ORDER == 5
        devcBSpline5(da, bspln_a_knots);
        devcBSpline5(db, bspln_b_knots);
        devcBSpline5(dc, bspln_c_knots);
#elif ORDER == 6
        devcBSpline6(da, bspln_a_knots);
        devcBSpline6(db, bspln_b_knots);
        devcBSpline6(dc, bspln_c_knots);
#endif
        for (int i = 0; i < pm_wrt.order; i++) {
          bspln_a_knots[i] *= q;
        }

        // Loop over all grid points, issuing atomic additions to the particle-mesh interaction
        // grid.
        const int gmap_a_limit = pmwu[10] * cgr.mesh_ticks;
        const int gmap_b_limit = pmwu[11] * cgr.mesh_ticks;
        const int gmap_c_limit = pmwu[12] * cgr.mesh_ticks;
        for (int i = 0; i < ORDER; i++) {
          for (int j = 0; j < ORDER; j++) {
            for (int k = 0; k < ORDER; k++) {
              if (i + ida >= 0 && i + ida < gmap_a_limit &&
                  j + idb >= 0 && j + idb < gmap_b_limit &&
                  k + idc >= 0 && k + idc < gmap_c_limit) {
                const size_t local_gpos = ((((k + idc) * gmap_b_limit) +
                                            j + idb) * gmap_a_limit) + i + ida;
                const TCALC dq = bspln_a_knots[i] * bspln_b_knots[j] * bspln_c_knots[k] *
                                 pm_wrt.shacc_fp_scale;
                atomicSplit(dq, local_gpos, primary, overflow);
              }
            }
          }
        }

        // Advance to the next batch of atoms
        atom_in_chain_pos += warp_size_int;
      }

      // Advance to the next chain.
      SYNCWARP;
      if (lane_idx == 0) {
        warp_pos[warp_idx] = atomicAdd((int*)&warp_progress, 1);
      }
      SYNCWARP;
    }
    __syncthreads();
    
    // Convert the results to real-valued numbers and write them to the density grid in global
    // memory.  While this will involve a global read of a lot of data that has likely left L1, the
    // data may still be preserved in L2
    for (int pos = threadIdx.x; pos < pmwu[17]; pos += blockDim.x) {
      
      // Compute the position in the work unit's grid-mapping region.
      const int local_a_len = pmwu[10] * cgr.mesh_ticks;
      const int local_ab_slab = local_a_len * pmwu[11] * cgr.mesh_ticks;
      const int local_cidx = pos / local_ab_slab;
      const int local_bidx = (pos - (local_cidx * local_ab_slab)) / local_a_len;
      const int local_aidx = pos - ((local_cidx * local_ab_slab) + (local_bidx * local_a_len));

      // Compute the position in the overall particle-mesh interaction grid.
      int gbl_aidx = (pmwu[7] * cgr.mesh_ticks) + local_aidx;
      int gbl_bidx = (pmwu[8] * cgr.mesh_ticks) + local_bidx;
      int gbl_cidx = (pmwu[9] * cgr.mesh_ticks) + local_cidx;
      gbl_aidx -= (gbl_aidx >= pmwu[18]) * pmwu[18];
      gbl_bidx -= (gbl_bidx >= pmwu[19]) * pmwu[19];
      gbl_cidx -= (gbl_cidx >= pmwu[20]) * pmwu[20];
      const uint gbl_pos = (((gbl_cidx * pmwu[19]) + gbl_bidx) * pmwu[18]) + gbl_aidx;

      // Read the primary accumulator in __shared__ and the overflow which received additional
      // atomic contributions in L2.  Use write-through stores, as these values are final and
      // should not pollute L1 or L2.  It is not useful to re-initialize the __global__ memory
      // space at this stage, as it is not known how extensive the next work unit will be.
#ifdef ACC_MODE_DOUBLE
      const int95_t ival = { primary[pos], overflow[pos] };
      const double qval = splitFPToReal(ival) / pm_wrt.shacc_fp_scale;
      __stwt(&pm_wrt.ddata[gbl_pos + pmwu[21]], qval);
#else
      const int2 ival = { primary[pos], overflow[pos] };
      const float qval = splitFPToReal(ival) / pm_wrt.shacc_fp_scale;
      __stwt(&pm_wrt.fdata[gbl_pos + pmwu[21]], qval);
#endif
    }
    __syncthreads();

    // Advance to the next work unit.
    if (warp_idx == 0) {
      if (threadIdx.x == 0) {
        const size_t prog_counter_idx = (ctrl.step & twice_warp_bits_mask_int);
        pmwu_idx = atomicAdd(&ctrl.pmewu_progress[prog_counter_idx], 1);
        warp_progress = (blockDim.x >> warp_bits);
      }
      SYNCWARP;
      if (pmwu_idx < pm_wrt.wu_count) {
        for (int pos = lane_idx; pos < density_mapping_wu_size; pos += warp_size_int) {
          pmwu[pos] = pm_wrt.work_units[(pmwu_idx * density_mapping_wu_size) + pos];
        }

        // Getting the same information again from L1 avoids the need for another SYNCWARP call
        const int sysid = pm_wrt.work_units[pmwu_idx * density_mapping_wu_size];
#if defined(STORMM_USE_CUDA) || defined(STORMM_USE_HIP) || defined(STORMM_USE_INTEL)
        if (lane_idx < 9) {
          cell_umat[lane_idx] = cgr.system_cell_umat[(sysid * warp_size_int) + lane_idx];
        }
#endif
        for (int pos = lane_idx; pos < (blockDim.x >> warp_bits); pos += warp_size_int) {
          warp_pos[pos] = pos;
        }
      }
    }
    else {

      // Reset all critical elements of the __shared__ and __global__ memory spaces.
      for (int pos = threadIdx.x - warp_size_int; pos < gmem_r.max_grid_points;
           pos += blockDim.x - warp_size_int) {
#ifdef ACC_MODE_DOUBLE
        primary[pos] = 0LL;
#else
        primary[pos] = 0;
#endif
        overflow[pos] = 0;
      }
    }
    __syncthreads();
  }

  // Set the block counters for future iterations of this kernel
  if (blockIdx.x == 0 && threadIdx.x < warp_size_int) {
    const int step_modulus = (ctrl.step & twice_warp_bits_mask_int);
    if (step_modulus == 0) {
      ctrl.pmewu_progress[threadIdx.x + warp_size_int] = gridDim.x;
    }
    if (step_modulus == warp_size_int) {
      ctrl.pmewu_progress[threadIdx.x] = gridDim.x;
    }
  }
}
